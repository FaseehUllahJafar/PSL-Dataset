# PSL Dataset

It uses 3 different types of datasets and gets mediapipe data from videos in the form if npy array and saves it in the npy file. To see the usage and how the data is obtained or processed please refer to [GDS---Gesture-Decode-System](https://github.com/FaseehUllahJafar/GDS---Gesture-Decode-System).

## Datasets

1.  PSL - Dataset from PSL website
2.  Schools/Professionals - Dataset from schools where sign language is taught
3.  Personal - Generated personaly

--------------------------------------------
## Video Statistics

- Number of Videos 'Ankle': 33
- Number of Videos 'Blood': 34
- Number of Videos 'Fist': 33
- Number of Videos 'Heart': 40
- Number of Videos 'Jaw': 35
- Number of Videos 'Knuckle': 41
- Number of Videos 'Lips': 35
- Number of Videos 'Palm': 38
- Number of Videos 'Skull': 45
- Number of Videos 'Thumb': 43
- Number of Videos 'Abdomen': 37
- Number of Videos 'Back': 40
- Number of Videos 'Body': 40
- Number of Videos 'Brain': 36
- Number of Videos 'Elbow': 36
- Number of Videos 'Finger': 35
- Number of Videos 'Gall Bladder': 43
- Number of Videos 'Intestine': 36
- Number of Videos 'Lungs': 39

----------------------------------

Minimum Number of Videos: 33

Maximum Number of Videos: 45
